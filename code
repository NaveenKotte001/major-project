import shutil
import tkinter as tk
from tkinter import filedialog
import os
import re
import cv2
from cvzone.HandTrackingModule import HandDetector
import numpy as np
import speech_recognition as sr

# Constants
width, height = 1920, 1080  # Full HD resolution for slide interaction

# Function to ask the user to select a folder using tkinter file dialog
def select_folder():
    root = tk.Tk()
    root.withdraw()  # Hide the main window
    folder_path = filedialog.askdirectory(title="Select Folder")
    if folder_path:
        return folder_path
    else:
        print("Folder selection cancelled.")
        return None

# Get the folder path selected by the user
selected_folder = select_folder()

def rename_png_files(folder_path):
    png_files = [file for file in os.listdir(folder_path) if file.endswith('.png')]
    png_files.sort()
    for index, old_name in enumerate(png_files, start=1):
        new_name = f"{index}.png"
        old_path = os.path.join(folder_path, old_name)
        new_path = os.path.join(folder_path, new_name)
        os.rename(old_path, new_path)
        print(f"Renamed: {old_name} -> {new_name}")

if selected_folder:
    rename_png_files(selected_folder)

# Camera setup
cap = cv2.VideoCapture(0)
cap.set(3, width)
cap.set(4, height)

# Image list
pattern = r"(\d+)"  # Regular expression pattern to extract numeric part
pathImages = sorted(os.listdir(selected_folder), key=lambda x: int(re.findall(pattern, x)[0]))

# Variables
imgno = 0
gestureThreshold = 300
buttonPressed = False
buttoncounter = 0
buttondelay = 15
annotations = [[]]
annotationNo = 0
annotationstart = False

# Hand detector with improved accuracy
det = HandDetector(detectionCon=0.95, maxHands=1)  # Increased detectionCon for higher accuracy

# Initialize speech recognizer
r = sr.Recognizer()

def recognize_speech():
    with sr.Microphone() as source:
        print("Listening for command...")
        try:
            audio = r.listen(source, timeout=5)  # Increased timeout to 5 seconds for better recognition
            command = r.recognize_google(audio).lower()
            print("Recognized: ", command)
            return command
        except (sr.UnknownValueError, sr.RequestError):
            print("Speech recognition failed or could not understand.")
            return None
        except Exception as e:
            print(f"An error occurred: {e}")
            return None

while True:
    # Capture the webcam feed
    success, img = cap.read()
    if not success:
        print("Failed to capture image from webcam.")
        break

    img = cv2.flip(img, 1)

    # Get the full image path
    if imgno < len(pathImages):
        pathFullimage = os.path.join(selected_folder, pathImages[imgno])
        imgcurr = cv2.imread(pathFullimage)
    else:
        print("No more images available.")
        break

    # Detect hands
    hands, img = det.findHands(img)

    # Draw gesture threshold line
    cv2.line(imgcurr, (0, gestureThreshold), (width, gestureThreshold), (0, 255, 0), 10)

    # Detect hands and handle gestures
    if hands and not buttonPressed:
        hand = hands[0]
        fingers = det.fingersUp(hand)
        cx, cy = hand['center']
        lmList = hand['lmList']

        # Constrain values for easier drawing of the pointer gesture.
        xVal = int(np.interp(lmList[8][0], [0, width], [0, width]))
        yVal = int(np.interp(lmList[8][1], [0, height], [0, height]))
        indexFinger = xVal, yVal

        # Gesture recognition logic.
        
        # Left gesture.
        if fingers == [1, 0, 0, 0, 0]:
            annotationstart = False
            print("left")
            if imgno > 0:
                buttonPressed = True
                annotations.append([])  # Reset annotations when changing images.
                annotationNo = 0
                imgno -= 1

        # Right gesture.
        elif fingers == [0, 0, 0, 0, 0]:
            annotationstart = False
            print("right")
            if imgno < len(pathImages) - 1:
                buttonPressed = True
                annotations.append([])  # Reset annotations when changing images.
                annotationNo = 0
                imgno += 1

        # Exit gesture.
        elif fingers == [1, 1, 0, 0, 1]:
            print("Exit gesture detected. Closing application.")
            cap.release()  
            cv2.destroyAllWindows()  
            break

        # Speech activation gesture (Index + Middle + Ring fingers raised).
        elif fingers == [0, 1, 1, 1, 1]:  
            print("Activating speech recognition...")
            command = recognize_speech()  
            if command:
                print(f"Command received: {command}")
                if "next" in command and imgno < len(pathImages) - 1:
                    imgno += 1
                elif "previous" in command and imgno > 0:
                    imgno -= 1
                elif "remove" in command and annotations:
                    if annotations:
                        annotations.pop(-1)
                        annotationNo -= min(1, annotationNo)  
                elif "exit" in command:
                    print("Exiting program based on speech command.")
                    cap.release()  
                    cv2.destroyAllWindows()  
                    break

        # Pointer gesture (Index finger raised).
        elif fingers == [0, 1, 0, 0, 0]:
            if not annotationstart: 
                annotationstart = True  
                annotationNo += 1  
                annotations.append([])  

            cv2.circle(imgcurr, indexFinger, 12, (255, 255, 255), cv2.FILLED)  
            annotations[annotationNo].append(indexFinger)  

        # Show pointer without adding an annotation.
        elif fingers == [0, 1, 1, 0, 0]:
            cv2.circle(imgcurr, indexFinger, 8, (255, 255,255), cv2.FILLED)  

        # Erase gesture (Index + Middle fingers raised).
        elif fingers == [0, 1, 1, 1 ,0]:
            if annotations and annotationNo > -1: 
                annotations.pop(-1)
                annotationNo -= min(1 , annotationNo) 
                buttonPressed = True  

    # Button pressed iterations.
    if buttonPressed:
        buttoncounter += 1 
        if buttoncounter > buttondelay: 
            buttoncounter = 0 
            buttonPressed = False 

    # Draw annotations.
    for i in range(len(annotations)):
        for j in range(len(annotations[i])):
            if j != 0:
                cv2.line(imgcurr , annotations[i][j -1] , annotations[i][j] , (255 ,255 ,255),12)

    # Resize webcam feed to a smaller size.
    webcam_height = int(height * .2)  
    webcam_width = int(width * .2)  
    imgsmall= cv2.resize(img , (webcam_width , webcam_height))

    # Place webcam feed at the bottom-right corner.
    imgcurr[-webcam_height:, -webcam_width:] = imgsmall 

    # Create a named window with resizable property.
    cv2.namedWindow("Image with Annotations", cv2.WINDOW_NORMAL)

    # Show the slide with annotations and webcam feed.
    cv2.imshow("Image with Annotations", imgcurr)

    key= cv2.waitKey(1)
    
# Release camera and close windows.
cap.release()
cv2.destroyAllWindows()
